{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4525cdb-809b-46bd-aeec-3d5ce015d22b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+------------+-------+-----------------+------------------+--------+\n|License_Issue_Date|License_Number|Animals_Name|Species|    Primary_Breed|   Secondary_Breed|ZIP_Code|\n+------------------+--------------+------------+-------+-----------------+------------------+--------+\n|  December 18 2015|       S107948|         Zen|    Cat|Domestic Longhair|               Mix|   98117|\n|      June 14 2016|       S116503|       Misty|    Cat|         Siberian|              null|   98117|\n|    August 04 2016|       S119301|        Lyra|    Cat|              Mix|              null|   98121|\n|    August 10 2019|       S133113|      Spider|    Cat|           LaPerm|              null|   98115|\n|  November 20 2020|         77412|       Gemma|    Cat|          Siamese|American Shorthair|   98126|\n+------------------+--------------+------------+-------+-----------------+------------------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", True) \\\n",
    "               .option(\"delimiter\", \"\\t\") \\\n",
    "               .csv(\"dbfs:/FileStore/shared_uploads/pekamwar.s@northeastern.edu/Seattle_Pet_Licenses_new__1_.tsv\")\n",
    "\n",
    "\n",
    "# Preview the data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fb7e21-4fc3-4738-bca5-17f5403b425a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|License_Issue_Date|\n+------------------+\n|2015-12-18        |\n|2016-06-14        |\n|2016-08-04        |\n|2019-08-10        |\n|2020-11-20        |\n+------------------+\nonly showing top 5 rows\n\nroot\n |-- License_Issue_Date: date (nullable = true)\n |-- License_Number: string (nullable = true)\n |-- Animals_Name: string (nullable = true)\n |-- Species: string (nullable = true)\n |-- Primary_Breed: string (nullable = true)\n |-- Secondary_Breed: string (nullable = true)\n |-- ZIP_Code: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Convert License_Issue_Date to a valid date format\n",
    "df = df.withColumn(\"License_Issue_Date\", to_date(\"License_Issue_Date\", \"MMMM dd yyyy\"))\n",
    "\n",
    "# Verify the conversion\n",
    "df.select(\"License_Issue_Date\").show(5, truncate=False)\n",
    "\n",
    "# Print schema to confirm data type change\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "248143df-4b1d-474a-846d-b075486eccee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- License_Issue_Date: date (nullable = true)\n |-- License_Number: integer (nullable = true)\n |-- Animals_Name: string (nullable = true)\n |-- Species: string (nullable = true)\n |-- Primary_Breed: string (nullable = true)\n |-- Secondary_Breed: string (nullable = true)\n |-- ZIP_Code: integer (nullable = true)\n\n+------------------+--------------+-------------+-------+------------------+------------------+--------+\n|License_Issue_Date|License_Number| Animals_Name|Species|     Primary_Breed|   Secondary_Breed|ZIP_Code|\n+------------------+--------------+-------------+-------+------------------+------------------+--------+\n|        2015-12-18|          null|          Zen|    Cat| Domestic Longhair|               Mix|   98117|\n|        2016-06-14|          null|        Misty|    Cat|          Siberian|              null|   98117|\n|        2016-08-04|          null|         Lyra|    Cat|               Mix|              null|   98121|\n|        2019-08-10|          null|       Spider|    Cat|            LaPerm|              null|   98115|\n|        2020-11-20|         77412|        Gemma|    Cat|           Siamese|American Shorthair|   98126|\n|        2021-02-03|       8004418|         Emme|    Cat|Domestic Shorthair|               Mix|   98136|\n|        2021-04-07|         19048|         Rudy|    Cat|Domestic Shorthair|              null|   98103|\n|        2021-04-09|       8004956|        Custo|    Cat|Domestic Shorthair|               Mix|   98117|\n|        2021-04-28|       8008321|         Cece|    Cat|American Shorthair|               Mix|   98125|\n|        2021-05-07|        273780|        Taffy|    Cat|           Siamese|               Mix|   98125|\n|        2021-05-28|          null|       Seamus|    Cat|Domestic Shorthair|               Mix|   98104|\n|        2021-07-19|       8029709|       Pippin|    Cat|           Persian|               Mix|   98105|\n|        2021-07-23|        133986|         Milo|    Cat|            LaPerm|              null|   98133|\n|        2021-07-23|       8030061|Luna Lovegood|    Cat| Domestic Longhair|               Mix|   98117|\n|        2021-08-03|          null|       Eugene|    Cat|Domestic Shorthair|               Mix|   98125|\n|        2021-08-19|       8010082|        Mouse|    Cat|Domestic Shorthair|              null|   98199|\n|        2021-09-21|       8031624|          Koa|    Cat|           Burmese|              null|   98125|\n|        2021-09-25|        140426|     Theodore|    Cat|Domestic Shorthair|              null|   98144|\n|        2021-10-21|         85529|         Cody|    Cat|American Shorthair|              null|   98105|\n|        2021-10-25|       8033726|         Binu|    Cat|Domestic Shorthair|               Mix|   98119|\n+------------------+--------------+-------------+-------+------------------+------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Convert ZIP_Code and License_Number to integer data type\n",
    "df = df.withColumn(\"ZIP_Code\", col(\"ZIP_Code\").cast(\"int\")) \\\n",
    "       .withColumn(\"License_Number\", col(\"License_Number\").cast(\"int\"))\n",
    "\n",
    "# Display the schema to confirm the changes\n",
    "df.printSchema()\n",
    "\n",
    "# Show a few rows to verify the data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6362760-27c0-47c9-ba10-726de5adc477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, monotonically_increasing_id, current_date, year, month, dayofweek, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261f4505-d678-4387-b047-3ebe2c06ff2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Breed_Dim = df.select(\"Species\", \"Primary_Breed\", \"Secondary_Breed\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .dropna() \\\n",
    "    .withColumn(\"Breed_SK\", monotonically_increasing_id() + 1) \\\n",
    "    .withColumn(\"DI_LOAD_Dt\", current_date()) \\\n",
    "    .select(\"Breed_SK\", \"Species\", \"Primary_Breed\", \"Secondary_Breed\", \"DI_LOAD_Dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22cdad84-fd97-4e36-8c5a-4224f2d9ca2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------------------+--------------------+----------+\n|Breed_SK|Species|       Primary_Breed|     Secondary_Breed|DI_LOAD_Dt|\n+--------+-------+--------------------+--------------------+----------+\n|       1|    Cat|            Balinese|                 Mix|2025-04-05|\n|       2|    Dog| Retriever, Labrador|               Hound|2025-04-05|\n|       3|    Dog|         Poodle, Toy|            Shepherd|2025-04-05|\n|       4|    Dog|   Poodle, Miniature|Dachshund, Miniat...|2025-04-05|\n|       5|    Dog|      Great Pyrenees|     German Shepherd|2025-04-05|\n|       6|    Dog|Chihuahua, Short ...|     Chinese Crested|2025-04-05|\n|       7|    Dog|             Whippet|Terrier, American...|2025-04-05|\n|       8|    Dog|   Poodle, Miniature|      Terrier, Cairn|2025-04-05|\n|       9|    Dog|   Doberman Pinscher|      Collie, Smooth|2025-04-05|\n|      10|    Dog|Australian Cattle...|        Basset Hound|2025-04-05|\n|      11|    Dog| Australian Shepherd|Dachshund, Standa...|2025-04-05|\n|      12|    Dog|  Terrier, Yorkshire| Schnauzer, Standard|2025-04-05|\n|      13|    Dog|          Pomeranian|Mixed Breed, Smal...|2025-04-05|\n|      14|    Dog|     Bulldog, French|  Bulldog, Victorian|2025-04-05|\n|      15|    Dog|Australian Cattle...|Chihuahua, Long Coat|2025-04-05|\n|      16|    Dog|     Chinese Crested|  Terrier, Yorkshire|2025-04-05|\n|      17|    Dog|      Siberian Husky|                 Mix|2025-04-05|\n|      18|    Dog|              Beagle|Pointer, German S...|2025-04-05|\n|      19|    Dog|Welsh Corgi, Card...|      Siberian Husky|2025-04-05|\n|      20|    Dog|          Rottweiler|   Retriever, Golden|2025-04-05|\n+--------+-------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\nroot\n |-- Breed_SK: long (nullable = false)\n |-- Species: string (nullable = true)\n |-- Primary_Breed: string (nullable = true)\n |-- Secondary_Breed: string (nullable = true)\n |-- DI_LOAD_Dt: date (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "Breed_Dim.show()  # Shows first 20 rows\n",
    "Breed_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9424d472-91c7-44d9-ae2c-09bafcbbbdd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Species_Dim = df.select(\"Species\").dropDuplicates().na.drop() \\\n",
    "    .withColumn(\"Species_SK\", monotonically_increasing_id() + 1) \\\n",
    "    .withColumn(\"DI_LOAD_Dt\", current_date()) \\\n",
    "    .select(\"Species_SK\", \"Species\", \"DI_LOAD_Dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d77ffcb-bcae-400b-93ce-3e91576f76a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+\n|Species_SK|Species|DI_LOAD_Dt|\n+----------+-------+----------+\n|         1|    Pig|2025-04-05|\n|         2|    Cat|2025-04-05|\n|         3|   Goat|2025-04-05|\n|         4|    Dog|2025-04-05|\n+----------+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "Species_Dim.show()  # Shows first 20.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbd0f7e-6120-4cf3-9c89-8439b60cc585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Species_SK: long (nullable = false)\n |-- Species: string (nullable = true)\n |-- DI_LOAD_Dt: date (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "Species_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe678844-273d-44ad-afe6-d821bc12597e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|      Date|\n+----------+\n|2015-01-01|\n|2015-01-02|\n|2015-01-03|\n|2015-01-04|\n|2015-01-05|\n+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, date_format, current_date, expr\n",
    "from pyspark.sql.types import DateType\n",
    "import datetime\n",
    "\n",
    "# Define the start and end dates for the range\n",
    "start_date = datetime.date(2015, 1, 1)  # Starting date\n",
    "end_date = datetime.date(2025, 12, 31)  # Ending date\n",
    "\n",
    "# Generate a list of dates between start_date and end_date\n",
    "date_list = [(start_date + datetime.timedelta(days=x)) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Create a DataFrame from the date list\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "date_df = spark.createDataFrame(date_list, DateType()).toDF(\"Date\")\n",
    "date_df.show(5)  # Display the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3a3d0aa-d6de-428e-8bda-d3f92449fa72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+---------+----------+\n|Date_SK|Year|Month_Name| Day_Name|DI_LOAD_Dt|\n+-------+----+----------+---------+----------+\n|      1|2015|   January| Thursday|2025-04-05|\n|      2|2015|   January|   Friday|2025-04-05|\n|      3|2015|   January| Saturday|2025-04-05|\n|      4|2015|   January|   Sunday|2025-04-05|\n|      5|2015|   January|   Monday|2025-04-05|\n|      6|2015|   January|  Tuesday|2025-04-05|\n|      7|2015|   January|Wednesday|2025-04-05|\n|      8|2015|   January| Thursday|2025-04-05|\n|      9|2015|   January|   Friday|2025-04-05|\n|     10|2015|   January| Saturday|2025-04-05|\n+-------+----+----------+---------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, dayofweek, date_format\n",
    "\n",
    "# Add attributes to create the Date Dimension Table\n",
    "Date_Dim = date_df \\\n",
    "    .withColumn(\"Date_SK\", monotonically_increasing_id() + 1) \\\n",
    "    .withColumn(\"Year\", year(\"Date\")) \\\n",
    "    .withColumn(\"Month_Name\", date_format(\"Date\", \"MMMM\")) \\\n",
    "    .withColumn(\"Day_Name\", date_format(\"Date\", \"EEEE\")) \\\n",
    "    .withColumn(\"DI_LOAD_Dt\", current_date()) \\\n",
    "    .select(\"Date_SK\", \"Year\", \"Month_Name\", \"Day_Name\", \"DI_LOAD_Dt\")\n",
    "\n",
    "# Display the Date Dimension Table\n",
    "Date_Dim.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62aa3720-f96f-4b33-8803-ad9eb1032b22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Date_SK: long (nullable = false)\n |-- Year: integer (nullable = true)\n |-- Month_Name: string (nullable = true)\n |-- Day_Name: string (nullable = true)\n |-- DI_LOAD_Dt: date (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "Date_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61f53b85-2404-47c3-8e77-fc418df72236",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Path: /Users/pekamwar.s@northeastern.edu/Untitled Notebook 2025-04-05 14:51:11\nFolder Path: /Users/pekamwar.s@northeastern.edu\n"
     ]
    }
   ],
   "source": [
    "# Get the current notebook path\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "\n",
    "# Extract the folder path (excluding the notebook name)\n",
    "folder_path = notebook_path[:notebook_path.rfind(\"/\")]\n",
    "\n",
    "print(f\"Notebook Path: {notebook_path}\")\n",
    "print(f\"Folder Path: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af893f0-fae6-49b7-9a52-1dc133db8d1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed_Dim saved at: /Users/pekamwar.s@northeastern.edu/Breed_Dim\n"
     ]
    }
   ],
   "source": [
    "# Define Delta table save path based on notebook folder\n",
    "delta_save_path = f\"/Users/pekamwar.s@northeastern.edu/Breed_Dim\"\n",
    "\n",
    "# Save Breed_Dim table\n",
    "Breed_Dim.write.format(\"delta\").mode(\"overwrite\").save(delta_save_path)\n",
    "\n",
    "print(f\"Breed_Dim saved at: {delta_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77156a64-1333-46c9-a07b-c189dfcfce97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: [FileInfo(path='dbfs:/Users/pekamwar.s@northeastern.edu/Breed_Dim/_delta_log/', name='_delta_log/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/Users/pekamwar.s@northeastern.edu/Breed_Dim/part-00000-2ba9428e-ddb6-4ac5-9b6c-55913e0ab69c-c000.snappy.parquet', name='part-00000-2ba9428e-ddb6-4ac5-9b6c-55913e0ab69c-c000.snappy.parquet', size=28620, modificationTime=1743879859000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(delta_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4affc46e-3e7c-41ad-b84a-6a6f7f8cf039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species_Dim saved at: /Users/pekamwar.s@northeastern.edu/Species_Dim\nDate_Dim saved at: /Users/pekamwar.s@northeastern.edu/Date_Dim\n"
     ]
    }
   ],
   "source": [
    "# Define Delta table save paths based on notebook folder\n",
    "species_dim_save_path = f\"/Users/pekamwar.s@northeastern.edu/Species_Dim\"\n",
    "date_dim_save_path = f\"/Users/pekamwar.s@northeastern.edu/Date_Dim\"\n",
    "\n",
    "\n",
    "# Save Species_Dim table\n",
    "Species_Dim.write.format(\"delta\").mode(\"overwrite\").save(species_dim_save_path)\n",
    "print(f\"Species_Dim saved at: {species_dim_save_path}\")\n",
    "\n",
    "# Save Date_Dim table\n",
    "Date_Dim.write.format(\"delta\").mode(\"overwrite\").save(date_dim_save_path)\n",
    "print(f\"Date_Dim saved at: {date_dim_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8497cb94-14f0-4163-9b10-721eaa1e4796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+-------+----------+----------+\n|state_fips|  state|state_abbr|zipcode|    county|      city|\n+----------+-------+----------+-------+----------+----------+\n|         1|Alabama|        AL|  35004| St. Clair|     Acmar|\n|         1|Alabama|        AL|  35005| Jefferson|Adamsville|\n|         1|Alabama|        AL|  35006| Jefferson|     Adger|\n|         1|Alabama|        AL|  35007|    Shelby|  Keystone|\n|         1|Alabama|        AL|  35010|Tallapoosa|  New site|\n+----------+-------+----------+-------+----------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_geo = spark.read.option(\"header\", True) \\\n",
    "               .csv(\"dbfs:/FileStore/shared_uploads/pekamwar.s@northeastern.edu/geo_data__1_.csv\")\n",
    "\n",
    "\n",
    "# Preview the data\n",
    "df_geo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8816fb04-4223-457f-ad16-7805486a5f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+--------+----------+----------+\n|state_fips|  state|state_abbr|ZIP_Code|    county|      city|\n+----------+-------+----------+--------+----------+----------+\n|         1|Alabama|        AL|   35004| St. Clair|     Acmar|\n|         1|Alabama|        AL|   35005| Jefferson|Adamsville|\n|         1|Alabama|        AL|   35006| Jefferson|     Adger|\n|         1|Alabama|        AL|   35007|    Shelby|  Keystone|\n|         1|Alabama|        AL|   35010|Tallapoosa|  New site|\n+----------+-------+----------+--------+----------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_geo = df_geo.withColumnRenamed(\"zipcode\", \"ZIP_Code\")\n",
    "df_geo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e868ee5-8edf-4105-9bd1-5ba993ea8dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Breed_SK</th><th>Species</th><th>Primary_Breed</th><th>Secondary_Breed</th><th>DI_LOAD_Dt</th></tr></thead><tbody><tr><td>1</td><td>Cat</td><td>Balinese</td><td>Mix</td><td>2025-04-05</td></tr><tr><td>2</td><td>Dog</td><td>Retriever, Labrador</td><td>Hound</td><td>2025-04-05</td></tr><tr><td>3</td><td>Dog</td><td>Poodle, Toy</td><td>Shepherd</td><td>2025-04-05</td></tr><tr><td>4</td><td>Dog</td><td>Poodle, Miniature</td><td>Dachshund, Miniature Smooth Haired</td><td>2025-04-05</td></tr><tr><td>5</td><td>Dog</td><td>Great Pyrenees</td><td>German Shepherd</td><td>2025-04-05</td></tr><tr><td>6</td><td>Dog</td><td>Chihuahua, Short Coat</td><td>Chinese Crested</td><td>2025-04-05</td></tr><tr><td>7</td><td>Dog</td><td>Whippet</td><td>Terrier, American Pit Bull</td><td>2025-04-05</td></tr><tr><td>8</td><td>Dog</td><td>Poodle, Miniature</td><td>Terrier, Cairn</td><td>2025-04-05</td></tr><tr><td>9</td><td>Dog</td><td>Doberman Pinscher</td><td>Collie, Smooth</td><td>2025-04-05</td></tr><tr><td>10</td><td>Dog</td><td>Australian Cattle Dog</td><td>Basset Hound</td><td>2025-04-05</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Cat",
         "Balinese",
         "Mix",
         "2025-04-05"
        ],
        [
         2,
         "Dog",
         "Retriever, Labrador",
         "Hound",
         "2025-04-05"
        ],
        [
         3,
         "Dog",
         "Poodle, Toy",
         "Shepherd",
         "2025-04-05"
        ],
        [
         4,
         "Dog",
         "Poodle, Miniature",
         "Dachshund, Miniature Smooth Haired",
         "2025-04-05"
        ],
        [
         5,
         "Dog",
         "Great Pyrenees",
         "German Shepherd",
         "2025-04-05"
        ],
        [
         6,
         "Dog",
         "Chihuahua, Short Coat",
         "Chinese Crested",
         "2025-04-05"
        ],
        [
         7,
         "Dog",
         "Whippet",
         "Terrier, American Pit Bull",
         "2025-04-05"
        ],
        [
         8,
         "Dog",
         "Poodle, Miniature",
         "Terrier, Cairn",
         "2025-04-05"
        ],
        [
         9,
         "Dog",
         "Doberman Pinscher",
         "Collie, Smooth",
         "2025-04-05"
        ],
        [
         10,
         "Dog",
         "Australian Cattle Dog",
         "Basset Hound",
         "2025-04-05"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Breed_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Species",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Primary_Breed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Secondary_Breed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DI_LOAD_Dt",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM delta.`/Users/pekamwar.s@northeastern.edu/Breed_Dim`\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7ea7169-69ca-4b10-a84b-b8f4fe71c862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- state_fips: string (nullable = true)\n |-- state: string (nullable = true)\n |-- state_abbr: string (nullable = true)\n |-- ZIP_Code: integer (nullable = true)\n |-- county: string (nullable = true)\n |-- city: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_geo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2643a6-0f1c-4e61-92d6-44036616ce29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- state_fips: string (nullable = true)\n |-- state: string (nullable = true)\n |-- state_abbr: string (nullable = true)\n |-- ZIP_Code: integer (nullable = true)\n |-- county: string (nullable = true)\n |-- city: string (nullable = true)\n\n+----------+-------+----------+--------+----------+------------+\n|state_fips|  state|state_abbr|ZIP_Code|    county|        city|\n+----------+-------+----------+--------+----------+------------+\n|         1|Alabama|        AL|   35004| St. Clair|       Acmar|\n|         1|Alabama|        AL|   35005| Jefferson|  Adamsville|\n|         1|Alabama|        AL|   35006| Jefferson|       Adger|\n|         1|Alabama|        AL|   35007|    Shelby|    Keystone|\n|         1|Alabama|        AL|   35010|Tallapoosa|    New site|\n|         1|Alabama|        AL|   35014| Talladega|      Alpine|\n|         1|Alabama|        AL|   35016|  Marshall|        Arab|\n|         1|Alabama|        AL|   35019|   Cullman|   Baileyton|\n|         1|Alabama|        AL|   35020| Jefferson|    Bessemer|\n|         1|Alabama|        AL|   35022| Jefferson|  Zcta 35022|\n|         1|Alabama|        AL|   35023| Jefferson|    Hueytown|\n|         1|Alabama|        AL|   35031|    Blount|Blountsville|\n|         1|Alabama|        AL|   35033|   Cullman|      Bremen|\n|         1|Alabama|        AL|   35034|      Bibb|       Brent|\n|         1|Alabama|        AL|   35035|      Bibb|  Brierfield|\n|         1|Alabama|        AL|   35036| Jefferson|   Brookside|\n|         1|Alabama|        AL|   35040|    Shelby|      Calera|\n|         1|Alabama|        AL|   35042|      Bibb| Centreville|\n|         1|Alabama|        AL|   35043|    Shelby|     Chelsea|\n|         1|Alabama|        AL|   35044| Talladega| Coosa pines|\n+----------+-------+----------+--------+----------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Convert zipcode column to integer type\n",
    "df_geo = df_geo.withColumn(\"ZIP_Code\", df_geo[\"ZIP_Code\"].cast(\"int\"))\n",
    "\n",
    "\n",
    "# Verify the schema to confirm the change\n",
    "df_geo.printSchema()\n",
    "\n",
    "# Show a few rows to verify the data\n",
    "df_geo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b05514cc-d4e2-4d1e-8fb5-9f5bacd18792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Location_Dim = df_geo.select(\"State\", \"City\", \"ZIP_Code\").dropDuplicates().dropna() \\\n",
    "    .withColumn(\"Location_SK\", monotonically_increasing_id() +1) \\\n",
    "    .withColumn(\"DI_LOAD_Dt\", current_date()) \\\n",
    "    .select(\"Location_SK\", \"State\", \"City\", \"ZIP_Code\", \"DI_LOAD_Dt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e859dfe-a464-473f-a9f5-41e9284c0b0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------------+--------+----------+\n|Location_SK|     State|           City|ZIP_Code|DI_LOAD_Dt|\n+-----------+----------+---------------+--------+----------+\n|          1|   Alabama|    Mount olive|   35117|2025-04-05|\n|          2|   Alabama|      Beaverton|   35544|2025-04-05|\n|          3|   Alabama|         Dozier|   36028|2025-04-05|\n|          4|   Arizona|        Phoenix|   85019|2025-04-05|\n|          5|  Arkansas|          Poyen|   72128|2025-04-05|\n|          6|  Arkansas|        Proctor|   72376|2025-04-05|\n|          7|  Arkansas|            Bay|   72411|2025-04-05|\n|          8|  Arkansas|           Onia|   72663|2025-04-05|\n|          9|  Arkansas|    Natural dam|   72948|2025-04-05|\n|         10|California|    Los angeles|   90013|2025-04-05|\n|         11|California|North hollywood|   91605|2025-04-05|\n|         12|California|         Covina|   91723|2025-04-05|\n|         13|California|       La verne|   91750|2025-04-05|\n|         14|California|     Mc farland|   93250|2025-04-05|\n|         15|California|     Strathmore|   93267|2025-04-05|\n|         16|California|         Fresno|   93722|2025-04-05|\n|         17|California|         Felton|   95018|2025-04-05|\n|         18|California| Fields landing|   95537|2025-04-05|\n|         19|California|     Georgetown|   95634|2025-04-05|\n|         20|California|       Sheridan|   95681|2025-04-05|\n+-----------+----------+---------------+--------+----------+\nonly showing top 20 rows\n\nroot\n |-- Location_SK: long (nullable = false)\n |-- State: string (nullable = true)\n |-- City: string (nullable = true)\n |-- ZIP_Code: integer (nullable = true)\n |-- DI_LOAD_Dt: date (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "Location_Dim.show()  # Shows first 20 rows\n",
    "Location_Dim.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9fd4fb37-97bd-4804-96d8-97f6213c04d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1309401348079964>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m Pet_Lic_Fact \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBreed_Dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSpecies\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPrimary_Breed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSecondary_Breed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mleft\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLocation_Dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzipcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mleft\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPet_Lic_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonotonically_increasing_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDI_LOAD_Dt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_date\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPet_Lic_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLicense_Issue_Date\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzipcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBreed_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLocation_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDI_LOAD_Dt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n",
       "\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n",
       "\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n",
       "\u001B[1;32m   2979\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   2980\u001B[0m \n",
       "\u001B[1;32m   2981\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3021\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n",
       "\u001B[1;32m   3022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [AMBIGUOUS_REFERENCE] Reference `DI_LOAD_Dt` is ambiguous, could be: [`DI_LOAD_Dt`, `DI_LOAD_Dt`]."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-1309401348079964>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m Pet_Lic_Fact \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBreed_Dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSpecies\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPrimary_Breed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSecondary_Breed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mleft\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLocation_Dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzipcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mleft\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPet_Lic_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmonotonically_increasing_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDI_LOAD_Dt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_date\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPet_Lic_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLicense_Issue_Date\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzipcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBreed_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLocation_SK\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDI_LOAD_Dt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   2979\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   2980\u001B[0m \n\u001B[1;32m   2981\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3021\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n\u001B[1;32m   3022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [AMBIGUOUS_REFERENCE] Reference `DI_LOAD_Dt` is ambiguous, could be: [`DI_LOAD_Dt`, `DI_LOAD_Dt`].",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [AMBIGUOUS_REFERENCE] Reference `DI_LOAD_Dt` is ambiguous, could be: [`DI_LOAD_Dt`, `DI_LOAD_Dt`].",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pet_Lic_Fact = df \\\n",
    "    .join(Breed_Dim, [\"Species\", \"Primary_Breed\", \"Secondary_Breed\"], \"left\") \\\n",
    "    .join(Location_Dim, \"ZIP_Code\", \"left\") \\\n",
    "    .withColumn(\"Pet_Lic_SK\", monotonically_increasing_id()+1) \\\n",
    "    .withColumn(\"DI_LOAD_Dt\", current_date()) \\\n",
    "    .select(\n",
    "        \"Pet_Lic_SK\",\n",
    "        \"License_Issue_Date\",\n",
    "        \"ZIP_Code\",\n",
    "        \"Breed_SK\",\n",
    "        \"Location_SK\",\n",
    "        \"DI_LOAD_Dt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "509c0786-a584-4b51-b9dd-a8a2dc072fdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Pet_Lic_SK: long (nullable = false)\n |-- License_Issue_Date: date (nullable = true)\n |-- ZIP_Code: integer (nullable = true)\n |-- Breed_SK: long (nullable = true)\n |-- Location_SK: long (nullable = true)\n\n+----------+------------------+--------+--------+-----------+\n|Pet_Lic_SK|License_Issue_Date|ZIP_Code|Breed_SK|Location_SK|\n+----------+------------------+--------+--------+-----------+\n|1         |2015-12-18        |98117   |262     |8172       |\n|2         |2016-06-14        |98117   |null    |8172       |\n|3         |2016-08-04        |98121   |null    |8970       |\n|4         |2019-08-10        |98115   |null    |23767      |\n|5         |2020-11-20        |98126   |1049    |16409      |\n+----------+------------------+--------+--------+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, current_date, monotonically_increasing_id\n",
    "\n",
    "# Add aliases to DataFrames\n",
    "df_alias = df.alias(\"fact\")\n",
    "Breed_Dim_alias = Breed_Dim.alias(\"breed\")\n",
    "Location_Dim_alias = Location_Dim.alias(\"location\")\n",
    "\n",
    "# Perform the join with aliases\n",
    "Pet_Lic_Fact = df_alias \\\n",
    "    .join(Breed_Dim_alias, [\"Species\", \"Primary_Breed\", \"Secondary_Breed\"], \"left\") \\\n",
    "    .join(Location_Dim_alias, [\"ZIP_Code\"], \"left\") \\\n",
    "    .withColumn(\"Pet_Lic_SK\", monotonically_increasing_id() + 1) \\\n",
    "    .withColumn(\"DI_LOAD_Dt\", current_date()) \\\n",
    "    .select(\n",
    "        col(\"Pet_Lic_SK\"),\n",
    "        col(\"fact.License_Issue_Date\"),\n",
    "        col(\"fact.ZIP_Code\"),\n",
    "        col(\"breed.Breed_SK\"),\n",
    "        col(\"location.Location_SK\")\n",
    "    )\n",
    "\n",
    "# Display schema and preview data\n",
    "Pet_Lic_Fact.printSchema()\n",
    "Pet_Lic_Fact.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55db850d-43cf-426e-9260-94a01890ac8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location_Dim saved at: /Users/pekamwar.s@northeastern.edu/Species_Dim\nPet_Lic_Fact saved at: /Users/pekamwar.s@northeastern.edu/Date_Dim\n"
     ]
    }
   ],
   "source": [
    "# Define Delta table save paths based on notebook folder\n",
    "location_dim_save_path = f\"/Users/pekamwar.s@northeastern.edu/Location_Dim\"\n",
    "fact_save_path = f\"/Users/pekamwar.s@northeastern.edu/Pet_Lic_Fact\"\n",
    "\n",
    "\n",
    "# Save Species_Dim table\n",
    "Location_Dim.write.format(\"delta\").mode(\"overwrite\").save(location_dim_save_path)\n",
    "print(f\"Location_Dim saved at: {species_dim_save_path}\")\n",
    "\n",
    "# Save Date_Dim table\n",
    "Pet_Lic_Fact.write.format(\"delta\").mode(\"overwrite\").save(fact_save_path)\n",
    "print(f\"Pet_Lic_Fact saved at: {date_dim_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b3bef73-c450-45c1-b7dc-15872ae22042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Breed_SK</th><th>Species</th><th>Primary_Breed</th><th>Secondary_Breed</th><th>DI_LOAD_Dt</th></tr></thead><tbody><tr><td>1</td><td>Cat</td><td>Balinese</td><td>Mix</td><td>2025-04-05</td></tr><tr><td>2</td><td>Dog</td><td>Retriever, Labrador</td><td>Hound</td><td>2025-04-05</td></tr><tr><td>3</td><td>Dog</td><td>Poodle, Toy</td><td>Shepherd</td><td>2025-04-05</td></tr><tr><td>4</td><td>Dog</td><td>Poodle, Miniature</td><td>Dachshund, Miniature Smooth Haired</td><td>2025-04-05</td></tr><tr><td>5</td><td>Dog</td><td>Great Pyrenees</td><td>German Shepherd</td><td>2025-04-05</td></tr><tr><td>6</td><td>Dog</td><td>Chihuahua, Short Coat</td><td>Chinese Crested</td><td>2025-04-05</td></tr><tr><td>7</td><td>Dog</td><td>Whippet</td><td>Terrier, American Pit Bull</td><td>2025-04-05</td></tr><tr><td>8</td><td>Dog</td><td>Poodle, Miniature</td><td>Terrier, Cairn</td><td>2025-04-05</td></tr><tr><td>9</td><td>Dog</td><td>Doberman Pinscher</td><td>Collie, Smooth</td><td>2025-04-05</td></tr><tr><td>10</td><td>Dog</td><td>Australian Cattle Dog</td><td>Basset Hound</td><td>2025-04-05</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Cat",
         "Balinese",
         "Mix",
         "2025-04-05"
        ],
        [
         2,
         "Dog",
         "Retriever, Labrador",
         "Hound",
         "2025-04-05"
        ],
        [
         3,
         "Dog",
         "Poodle, Toy",
         "Shepherd",
         "2025-04-05"
        ],
        [
         4,
         "Dog",
         "Poodle, Miniature",
         "Dachshund, Miniature Smooth Haired",
         "2025-04-05"
        ],
        [
         5,
         "Dog",
         "Great Pyrenees",
         "German Shepherd",
         "2025-04-05"
        ],
        [
         6,
         "Dog",
         "Chihuahua, Short Coat",
         "Chinese Crested",
         "2025-04-05"
        ],
        [
         7,
         "Dog",
         "Whippet",
         "Terrier, American Pit Bull",
         "2025-04-05"
        ],
        [
         8,
         "Dog",
         "Poodle, Miniature",
         "Terrier, Cairn",
         "2025-04-05"
        ],
        [
         9,
         "Dog",
         "Doberman Pinscher",
         "Collie, Smooth",
         "2025-04-05"
        ],
        [
         10,
         "Dog",
         "Australian Cattle Dog",
         "Basset Hound",
         "2025-04-05"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Breed_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Species",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Primary_Breed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Secondary_Breed",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DI_LOAD_Dt",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM delta.`/Users/pekamwar.s@northeastern.edu/Breed_Dim`\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c7a55bc-7c9c-4377-84ea-0bec8886b670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Species_SK</th><th>Species</th><th>DI_LOAD_Dt</th></tr></thead><tbody><tr><td>1</td><td>Pig</td><td>2025-04-05</td></tr><tr><td>2</td><td>Cat</td><td>2025-04-05</td></tr><tr><td>3</td><td>Goat</td><td>2025-04-05</td></tr><tr><td>4</td><td>Dog</td><td>2025-04-05</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Pig",
         "2025-04-05"
        ],
        [
         2,
         "Cat",
         "2025-04-05"
        ],
        [
         3,
         "Goat",
         "2025-04-05"
        ],
        [
         4,
         "Dog",
         "2025-04-05"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Species_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Species",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DI_LOAD_Dt",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM delta.`/Users/pekamwar.s@northeastern.edu/Species_Dim`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523062d1-eab1-4f75-ba73-e669763346c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Date_SK</th><th>Year</th><th>Month_Name</th><th>Day_Name</th><th>DI_LOAD_Dt</th></tr></thead><tbody><tr><td>1</td><td>2015</td><td>January</td><td>Thursday</td><td>2025-04-05</td></tr><tr><td>2</td><td>2015</td><td>January</td><td>Friday</td><td>2025-04-05</td></tr><tr><td>3</td><td>2015</td><td>January</td><td>Saturday</td><td>2025-04-05</td></tr><tr><td>4</td><td>2015</td><td>January</td><td>Sunday</td><td>2025-04-05</td></tr><tr><td>5</td><td>2015</td><td>January</td><td>Monday</td><td>2025-04-05</td></tr><tr><td>6</td><td>2015</td><td>January</td><td>Tuesday</td><td>2025-04-05</td></tr><tr><td>7</td><td>2015</td><td>January</td><td>Wednesday</td><td>2025-04-05</td></tr><tr><td>8</td><td>2015</td><td>January</td><td>Thursday</td><td>2025-04-05</td></tr><tr><td>9</td><td>2015</td><td>January</td><td>Friday</td><td>2025-04-05</td></tr><tr><td>10</td><td>2015</td><td>January</td><td>Saturday</td><td>2025-04-05</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         2015,
         "January",
         "Thursday",
         "2025-04-05"
        ],
        [
         2,
         2015,
         "January",
         "Friday",
         "2025-04-05"
        ],
        [
         3,
         2015,
         "January",
         "Saturday",
         "2025-04-05"
        ],
        [
         4,
         2015,
         "January",
         "Sunday",
         "2025-04-05"
        ],
        [
         5,
         2015,
         "January",
         "Monday",
         "2025-04-05"
        ],
        [
         6,
         2015,
         "January",
         "Tuesday",
         "2025-04-05"
        ],
        [
         7,
         2015,
         "January",
         "Wednesday",
         "2025-04-05"
        ],
        [
         8,
         2015,
         "January",
         "Thursday",
         "2025-04-05"
        ],
        [
         9,
         2015,
         "January",
         "Friday",
         "2025-04-05"
        ],
        [
         10,
         2015,
         "January",
         "Saturday",
         "2025-04-05"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Date_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Year",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Month_Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Day_Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DI_LOAD_Dt",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM delta.`/Users/pekamwar.s@northeastern.edu/Date_Dim`\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183a85f4-8655-4e71-bbd1-650121d5e6f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Location_SK</th><th>State</th><th>City</th><th>ZIP_Code</th><th>DI_LOAD_Dt</th></tr></thead><tbody><tr><td>1</td><td>Alabama</td><td>Mount olive</td><td>35117</td><td>2025-04-05</td></tr><tr><td>2</td><td>Alabama</td><td>Beaverton</td><td>35544</td><td>2025-04-05</td></tr><tr><td>3</td><td>Alabama</td><td>Dozier</td><td>36028</td><td>2025-04-05</td></tr><tr><td>4</td><td>Arizona</td><td>Phoenix</td><td>85019</td><td>2025-04-05</td></tr><tr><td>5</td><td>Arkansas</td><td>Poyen</td><td>72128</td><td>2025-04-05</td></tr><tr><td>6</td><td>Arkansas</td><td>Proctor</td><td>72376</td><td>2025-04-05</td></tr><tr><td>7</td><td>Arkansas</td><td>Bay</td><td>72411</td><td>2025-04-05</td></tr><tr><td>8</td><td>Arkansas</td><td>Onia</td><td>72663</td><td>2025-04-05</td></tr><tr><td>9</td><td>Arkansas</td><td>Natural dam</td><td>72948</td><td>2025-04-05</td></tr><tr><td>10</td><td>California</td><td>Los angeles</td><td>90013</td><td>2025-04-05</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Alabama",
         "Mount olive",
         35117,
         "2025-04-05"
        ],
        [
         2,
         "Alabama",
         "Beaverton",
         35544,
         "2025-04-05"
        ],
        [
         3,
         "Alabama",
         "Dozier",
         36028,
         "2025-04-05"
        ],
        [
         4,
         "Arizona",
         "Phoenix",
         85019,
         "2025-04-05"
        ],
        [
         5,
         "Arkansas",
         "Poyen",
         72128,
         "2025-04-05"
        ],
        [
         6,
         "Arkansas",
         "Proctor",
         72376,
         "2025-04-05"
        ],
        [
         7,
         "Arkansas",
         "Bay",
         72411,
         "2025-04-05"
        ],
        [
         8,
         "Arkansas",
         "Onia",
         72663,
         "2025-04-05"
        ],
        [
         9,
         "Arkansas",
         "Natural dam",
         72948,
         "2025-04-05"
        ],
        [
         10,
         "California",
         "Los angeles",
         90013,
         "2025-04-05"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Location_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "State",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "City",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ZIP_Code",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "DI_LOAD_Dt",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM delta.`/Users/pekamwar.s@northeastern.edu/Location_Dim`\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ecc4dcd-9c97-4073-86ce-0640ff9e80fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Pet_Lic_SK</th><th>License_Issue_Date</th><th>ZIP_Code</th><th>Breed_SK</th><th>Location_SK</th></tr></thead><tbody><tr><td>1</td><td>2015-12-18</td><td>98117</td><td>262</td><td>8172</td></tr><tr><td>5</td><td>2020-11-20</td><td>98126</td><td>1049</td><td>16409</td></tr><tr><td>6</td><td>2021-02-03</td><td>98136</td><td>2746</td><td>31093</td></tr><tr><td>8</td><td>2021-04-09</td><td>98117</td><td>2746</td><td>8172</td></tr><tr><td>9</td><td>2021-04-28</td><td>98125</td><td>2824</td><td>6615</td></tr><tr><td>10</td><td>2021-05-07</td><td>98125</td><td>2259</td><td>6615</td></tr><tr><td>11</td><td>2021-05-28</td><td>98104</td><td>2746</td><td>6280</td></tr><tr><td>12</td><td>2021-07-19</td><td>98105</td><td>200</td><td>31582</td></tr><tr><td>14</td><td>2021-07-23</td><td>98117</td><td>262</td><td>8172</td></tr><tr><td>15</td><td>2021-08-03</td><td>98125</td><td>2746</td><td>6615</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "2015-12-18",
         98117,
         262,
         8172
        ],
        [
         5,
         "2020-11-20",
         98126,
         1049,
         16409
        ],
        [
         6,
         "2021-02-03",
         98136,
         2746,
         31093
        ],
        [
         8,
         "2021-04-09",
         98117,
         2746,
         8172
        ],
        [
         9,
         "2021-04-28",
         98125,
         2824,
         6615
        ],
        [
         10,
         "2021-05-07",
         98125,
         2259,
         6615
        ],
        [
         11,
         "2021-05-28",
         98104,
         2746,
         6280
        ],
        [
         12,
         "2021-07-19",
         98105,
         200,
         31582
        ],
        [
         14,
         "2021-07-23",
         98117,
         262,
         8172
        ],
        [
         15,
         "2021-08-03",
         98125,
         2746,
         6615
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Pet_Lic_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "License_Issue_Date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "ZIP_Code",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Breed_SK",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Location_SK",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM delta.`/Users/pekamwar.s@northeastern.edu/Pet_Lic_Fact`\n",
    "where Breed_SK is NOT NULL\n",
    "LIMIT 10;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1309401348079973,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Seattle_Dims_Fact",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}